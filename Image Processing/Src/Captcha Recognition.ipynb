{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['samples']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from keras import layers,callbacks\n",
    "from keras.models import Model,load_model\n",
    "import string\n",
    "print(os.listdir('Dataset/captcha-version-2-images'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Symbols contains the letters posssible in images.\n",
    "Images are of shape 50*200*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "Symbols = string.ascii_lowercase + string.ascii_uppercase + \"0123456789\"\n",
    "num_Symbols = len(Symbols)\n",
    "print(num_Symbols)\n",
    "img_shape = (50, 200, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images  1070\nSize of training dataset(images and labels) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (900, 50, 200) (900, 5, 62)\nSize of testing dataset(images and labels)  (170, 50, 200) (170, 5, 62)\n"
     ]
    }
   ],
   "source": [
    "def data_pre_processing():\n",
    "    num_samples = len(os.listdir('Dataset/captcha-version-2-images/samples'))\n",
    "    print('Number of images ', num_samples)\n",
    "    X = np.zeros((num_samples, 50, 200))                    # 1070*50*200*1\n",
    "    Y = np.zeros((num_samples, 5, num_Symbols))               # 1070*5*62\n",
    "    # print(X.shape)\n",
    "    # print(Y.shape)\n",
    "    \n",
    "    for i, pic in enumerate(os.listdir('Dataset/captcha-version-2-images/samples')):\n",
    "        \n",
    "        # i is used as enumerating index\n",
    "        # pic contains the name of image e.g. \"name\".png\n",
    "        img = cv2.imread(os.path.join('Dataset/captcha-version-2-images/samples', pic), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        name_of_image = pic[:-4]\n",
    "        \n",
    "        # if valid CAPTCHA resize the image\n",
    "        if len(name_of_image) < 6:\n",
    "            # scaling and resizing the image\n",
    "            img = img/255\n",
    "            img = cv2.resize(img, (200, 50))\n",
    "            \n",
    "            # define a matrix to ark all the charaters present in image as 1 and rest all as 0\n",
    "            chars = np.zeros((5,num_Symbols))\n",
    "            \n",
    "            for index in range(0, len(name_of_image)):\n",
    "                l = Symbols.find(name_of_image[index])\n",
    "                chars[index, l] = 1\n",
    "            \n",
    "            X[i] = img\n",
    "            Y[i] = chars\n",
    "            \n",
    "    return X, Y\n",
    "\n",
    "# X contains the images and Y their labels \n",
    "# i.e. X[i] has the CAPTCHA image and Y[i] has its CAPTCHA label\n",
    "\n",
    "\n",
    "X, Y = data_pre_processing()\n",
    "\n",
    "# divide the datasest into test and train dataset\n",
    "# out of 1070 images we will take 900 as training images and 170 as test images\n",
    "\n",
    "# TODO\n",
    "#     add validation set \n",
    "#     take the sizes of test and training set as hyperparameters\n",
    "    \n",
    "    \n",
    "X_train, Y_train = X[:900], Y[:900]\n",
    "X_test, Y_test = X[900:], Y[900:]\n",
    "print(\"Size of training dataset(images and labels) \", X_train.shape, Y_train.shape)\n",
    "print(\"Size of testing dataset(images and labels) \", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we define the model:\n",
    "The model will be sequential then Conv and dense layers.\n",
    "\n",
    "((CONV(RELU)->DROP)*2->POOL)*2->(FC(RELU)->DROP)*2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nconv2d_133_input (InputLayer)   (None, 50, 200, 1)   0                                            \n__________________________________________________________________________________________________\nconv2d_133 (Conv2D)             (None, 48, 198, 32)  320         conv2d_133_input[0][0]           \n__________________________________________________________________________________________________\ndropout_277 (Dropout)           (None, 48, 198, 32)  0           conv2d_133[0][0]                 \n__________________________________________________________________________________________________\nconv2d_134 (Conv2D)             (None, 46, 196, 32)  9248        dropout_277[0][0]                \n__________________________________________________________________________________________________\ndropout_278 (Dropout)           (None, 46, 196, 32)  0           conv2d_134[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling2d_67 (MaxPooling2D) (None, 23, 98, 32)   0           dropout_278[0][0]                \n__________________________________________________________________________________________________\nconv2d_135 (Conv2D)             (None, 21, 96, 32)   9248        max_pooling2d_67[0][0]           \n__________________________________________________________________________________________________\ndropout_279 (Dropout)           (None, 21, 96, 32)   0           conv2d_135[0][0]                 \n__________________________________________________________________________________________________\nconv2d_136 (Conv2D)             (None, 19, 94, 32)   9248        dropout_279[0][0]                \n__________________________________________________________________________________________________\ndropout_280 (Dropout)           (None, 19, 94, 32)   0           conv2d_136[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling2d_68 (MaxPooling2D) (None, 9, 47, 32)    0           dropout_280[0][0]                \n__________________________________________________________________________________________________\ndense_256 (Dense)               (None, 9, 47, 64)    2112        max_pooling2d_68[0][0]           \n__________________________________________________________________________________________________\ndropout_281 (Dropout)           (None, 9, 47, 64)    0           dense_256[0][0]                  \n__________________________________________________________________________________________________\nflatten_2 (Flatten)             (None, 27072)        0           dropout_281[0][0]                \n__________________________________________________________________________________________________\ndense_257 (Dense)               (None, 64)           1732672     flatten_2[0][0]                  \n__________________________________________________________________________________________________\ndense_259 (Dense)               (None, 64)           1732672     flatten_2[0][0]                  \n__________________________________________________________________________________________________\ndense_261 (Dense)               (None, 64)           1732672     flatten_2[0][0]                  \n__________________________________________________________________________________________________\ndense_263 (Dense)               (None, 64)           1732672     flatten_2[0][0]                  \n__________________________________________________________________________________________________\ndense_265 (Dense)               (None, 64)           1732672     flatten_2[0][0]                  \n__________________________________________________________________________________________________\ndropout_282 (Dropout)           (None, 64)           0           dense_257[0][0]                  \n__________________________________________________________________________________________________\ndropout_283 (Dropout)           (None, 64)           0           dense_259[0][0]                  \n__________________________________________________________________________________________________\ndropout_284 (Dropout)           (None, 64)           0           dense_261[0][0]                  \n__________________________________________________________________________________________________\ndropout_285 (Dropout)           (None, 64)           0           dense_263[0][0]                  \n__________________________________________________________________________________________________\ndropout_286 (Dropout)           (None, 64)           0           dense_265[0][0]                  \n__________________________________________________________________________________________________\ndense_258 (Dense)               (None, 62)           4030        dropout_282[0][0]                \n__________________________________________________________________________________________________\ndense_260 (Dense)               (None, 62)           4030        dropout_283[0][0]                \n__________________________________________________________________________________________________\ndense_262 (Dense)               (None, 62)           4030        dropout_284[0][0]                \n__________________________________________________________________________________________________\ndense_264 (Dense)               (None, 62)           4030        dropout_285[0][0]                \n__________________________________________________________________________________________________\ndense_266 (Dense)               (None, 62)           4030        dropout_286[0][0]                \n==================================================================================================\nTotal params: 8,713,686\nTrainable params: 8,713,686\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    # define the input\n",
    "    # img = layers.Input(img_shape)\n",
    "    \n",
    "    # define sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # (CONV(RELU)->DROP)*2->POOL)*2\n",
    "    \n",
    "    # 32 filter each with (3,3) size, stride =1 and no padding, relu activation \n",
    "    # specify input shape which is done only in first layer rest all layers take care of it automatically \n",
    "    model.add(Conv2D(32, (3, 3), padding='valid', activation='relu', input_shape=img_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(32, (3, 3), padding='valid', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    # max pool with pool size = 2 and strides = 2 will discard 75% activations\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "    model.add(Conv2D(32, (3, 3), padding='valid', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(32, (3, 3), padding='valid', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "    # (FC(RELU)->DROP)\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # layer = model.layers[len(model.layers)-1].output\n",
    "    # print(layer)\n",
    "    \n",
    "    # now flatten the model and split into 5 branches \n",
    "    # each branch will predict one letter in CAPTCHA\n",
    "    model.add(Flatten())\n",
    "    outs = []\n",
    "    for i in range(0, 5):\n",
    "        temp = model.layers[len(model.layers)-1].output\n",
    "        temp1 = layers.Dense(64, activation='relu')(temp)\n",
    "        temp2 = layers.Dropout(0.5)(temp1)\n",
    "        temp3 = layers.Dense(num_Symbols, activation='sigmoid')(temp2)\n",
    "        outs.append(temp3)\n",
    "        \n",
    "    # making a new model with input as the one in previous and output as outs layer\n",
    "    model = Model(inputs=model.input, outputs=outs)\n",
    "    \n",
    "    # visualize the architecture of model\n",
    "    model.summary()\n",
    "    \n",
    "    # compile the model using \n",
    "    model.compile(optimizer=, loss='categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "create_model()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
